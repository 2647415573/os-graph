

--- Page 337 ---
计算机操作系统
的消息。
(3）消息分为请求消息、应答消息和撤销消息三种，每个进程队列中的请求消息根据
事件时序排序，队列初始为空。
(4）进程Pi发送的请求消息形如request(Ti，i)，其中 Ti=Ci，是进程Pi发送此消息时
对应的逻辑时钟值，i代表消息内容。
面包房算法描述如下：
(1）当进程Pi请求资源时，它把请求消息request(Ti,i)排在自己的请求队列中，同时也
把该消息发送给系统中的其它进程；
(2）当进程Pj接收到外来消息request(Ti,i)后，发送回答消息reply(Tj,j)，并把request(Ti,i)
放入自己的请求队列。应当说明，若进程Pj在收到request(Ti，i)前已提出过对同一资源的
访问请求，那么其时间戳应比（Ti，i)小。
(3）若满足下述两条件，则允许进程Pi访问该资源（即允许进入临界区）：
·Pi自身请求访问该资源的消息已处于请求队列的最前面；
·Pi已收到从所有其它进程发来的回答消息，这些回答消息的时间戳均晚于（Ti，i)。
（4）为了释放该资源，Pi从自己的队列中撤销请求消息，并发送一个打上时间戳的释
放消息release给其它进程；
(5）当进程Pj收到Pi的release消息后，它撤销自己队列中的原Pi的request(Ti,i)消息。
10.4.7令牌环算法
一一一一一一→
该算法属于分布式同步算法，是将所有进程组成一个逻辑环(LogicalRing)，系统中设
置一个象征存取权力的令牌（Token)，它是一种特定格式的报文，在进程所组成的逻辑环中，
不断地循环传递，获得令牌的进程，才有权力进入临界区，访问共享资源。
个进程获得令牌时，如果不需要访问共享资源，则将令牌继续传递下去。否则，保持令牌，
对共享资源进行检查，如果其空闲，则进入临界区进行访问。访问结束退出临界区后，再
将令牌继续传递下去。进程利用令牌，每次只能访问一次共享资源。
显然，由于令牌只有一个，任何一个时刻，只有一个进程能够持有令牌，因此能实现
对共享资源的互斥访问。
为保证环中进程能实现对共享资源的访问，逻辑环中的令牌必须保持循环传递和不丢
失，如果因通信链路、进程故障等原因造成令牌被破坏或丢失，必须有机制及时修复，比
如重新颁发令牌，或者屏蔽故障进程，重构逻辑环等。该算法的不足之处在于，如果令牌
丢失或破坏，不便进行检测和判断。
/10.5多处理机系统的进程调度
在多处理机系统中，进程的调度与系统结构有关。例如，在同构型系统中，由于所有
的处理机都是相同的，因而可将进程分配到任一处理机上运行；但对于非对称多处理机系
326

--- Page 338 ---
第十章多处理机操作系统
统，则只能把进程分配到适合于它运行的处理机上去执行。
10.5.1评价调度性能的若干因素
一
评价多处理机调度性能的因素有如下几个：
1.任务流时间
把完成任务所需要的时间定义为任务流时间，例如，如图10-6所示，图中有三台处理
机P1～P3和五个任务T1～T5，调度从时间0开始，共运行了7个时间单位，在处理机P1
上运行任务T1和T2，分别需要5个和1.5个时间单位；在处理机P2上运行任务T2和
T1，分别用了5个和2个时间单位；在处理机P3上运行任务T3、T4和T5，每一个都需
要2个时间单位。因此，完成任务T1共需要5+2=7个时间单位，而完成任务T2共需
要5+1.5=6.5个时间单位。
P1
T1
T2
P2
T2
T1
P3T3 T4
T5
—$
时间
0123456
图10-6任务流和调度流示意图
2.调度流时间
在多处理机系统中，任务可以被分配到多个处理机上去运行。一个调度流时间是系统
中所有处理机上的任务流时间的总和。在如图10-6所示的例子中，在三台处理机上，调度
流时间=T1流+T2流+T3流+T4流+T5流=7+6.5+2+2+2=19.5（个时间单位）。
3.平均流
平均流等于调度流时间除以任务数。平均流时间越小，表示任务占用处理机与存储器
等资源的时间越短，这不仅反应了系统资源利用率高，而且还可以降低任务的机时费用。
更为重要的是，还可使系统有更充裕的时间处理其它任务，有效地提高了系统的吞吐量。
因此，最少平均流时间就是系统吞吐率的一个间接度量参数。
4.处理机利用率
处理机的利用率等于该处理机上任务流之和除以最大有效时间单位。在如图10-7所示的
例子中，最大有效时间单位为7.0，三台处理机P1、P2、P3的空闲时间分别为0.5、0.0和1.0，
忙时间分别为6.5、7.0、6.0，它们为各处理机上的任务流之和。由此可以得到P1、P2、P3
的处理机利用率分别为0.93、1.00和0.86。处理机平均利用率=（0.93+1.00+0.86）÷3=0.93。
5.加速比
加速比等于各处理机忙时间之和除以并行工作时间，其中，各处理机忙时间之和，相
开始到最后一个任务结束所用的时间，在上例中为7个时间单位。由此得到加速比为19.5
个时间单位/7个时间单位。
加速比用于度量多处理机系统的加速程度。处理机台数越多，调度流时间越大，与单
327

--- Page 339 ---
计算机操作系统
机相比其完成任务的速度越快，但是较少的处理机可减少成本。对于给定的任务，占用较
少的处理机可腾出更多的处理机，用于其它任务，从而使系统的总体性能得到提高。
6.吞吐率
吞吐率是单位时间（例如每小时)内系统完成的任务数。可以用任务流的最小完成时间
来度量系统的吞吐率。吞吐率的高低与调度算法有着十分密切的关系，通常具有多项式复
杂性的调度算法是一个高效的算法。而具有指数复杂性的调度算法则是一个低效算法。在
很多情况下，求解最优调度是NP完全性问题（NondeterministicPolynomial问题），意味着在
最坏情况下求解最优调度是非常困难的。但如果只考虑典型输入情况下的一个合适解，则
并不是一个难解的NP问题，因此，可以得到一组并行进程的合适调度。一般所说的优化
调度或最优调度，实际上均是指合适调度。
10.5.2进程分配方式
1.对称多处理机系统中的进程分配方式
在SMP系统中，所有的处理机都是相同的，因而可把所有的处理机作为一个处理机池
(Processorpool)，由调度程序或基于处理器的请求，将任何一个进程分配给池中的任何一个
处理机去处理。对于这种进程分配，可采用以下两种方式之一。
1）静态分配（StaticAssigenment)方式
时，须为每一处理器设置一专用的就绪队列，该队列中的诸进程先后都是被分配到该处理
器上执行。在进程阻塞后再次就绪时，也仍被挂在这个就绪队列中，因而下次它仍在此处
理器上执行。这种方式与单处理机环境下的进程调度一样。其优点是进程调度的开销小；缺
点是会使各处理器的忙闲不均。换言之，系统中可能有些处理机的就绪队列很快就变成空
队列，使处理器处于空闲状态，而另一些处理器则可能一直忙碌。
2）动态分配（DynamicAssgement)方式
为了防止系统中的多个处理器忙闲不均，可以在系统中仅设置一个公共的就绪队列，
系统中的所有就绪进程都被放在该队列中。分配进程时，可将进程分配到任何一个处理器
上。这样，对一个进程的整个运行过程而言，在每次被调度执行时，都是随机地被分配到
当时是空闲的某一处理器上去执行。例如，某进程一开始是被分配到处理器A上去执行，
后来因阻塞而放弃处理器A。当它又恢复为就绪状态后，就被挂到公共的就绪队列上，在
下次被调度时，就可能被分配到处理器B上去执行，也有可能被分配到处理器C或处理器
D上去执行。人们把这种方式称为动态分配方式。
动态分配方式的主要优点是消除了各处理器忙闲不均的现象。对于紧密耦合共享存储
器的MIPS，其每个处理器保存在存储器中的进程信息可被所有的处理器共享。因此这种调
度方式不会增加调度开销。但对于松散耦合的系统，在把一个在处理器A上运行的进程转
至在处理器B上运行时，还必须将在A处理器中所保存的该进程信息传送给处理器B，这
无疑会造成调度开销的明显增加。
2.非对称MPS中的进程分配方式
对于非对称MPS，其Os大多采用主一从(MasterSlave)式OS，即OS的核心部分驻留
328

--- Page 340 ---
第十章多处理机操作系统
在一台主机上(Master)，而从机(Slave)上只是用户程序，进程调度只由主机执行。每当从机
空闲时，便向主机发送一索求进程的信号，然后，便等待主机为它分配进程。在主机中保
持有一个就绪队列，只要就绪队列不空，主机便从其队首摘下一进程分配给请求的从机。
从机接收到分配的进程后便运行该进程，该进程结束后从机又向主机发出请求。
在非对称MPS中，主/从式的进程分配方式的主要优点是系统处理比较简单，这是因
为所有的进程分配都由一台主机独自处理，使进程间的同步问题得以简化，且进程调度程
序也很易于从单处理机的进程调度程序演化而来。但由一台主机控制一切，也潜在着不可
靠性，即主机一旦出现故障，将会导致整个系统瘫痪，而且也很易于因主机太忙，来不及
处理而形成系统瓶颈。克服这些缺点的有效方法是利用多台而非一台处理机来管理整个系
运行，而且用多台处理机（主）还可具有更强的执行管理任务的功能，更不容易形成系统瓶颈。
10.5.3进程（线程)调度方式
+一：
MPS已广为流行多年，相应地，也必然存在着多种调度方式，特别是自20世纪90年
代以来，已出现了多种调度方式，其中有许多都是以线程作为基本调度单位的。比较有代
表性的进（线）程调度方式有：自调度方式、成组调度方式和专用处理机分配方式等。
1.自调度（Self-Scheduling)方式
1）自调度机制
在多处理器系统中，自调度方式是最简单的一种调度方式。它是直接由单处理机环境
下的调度方式演变而来的。在系统中设置有一个公共的进程或线程就绪队列，所有的处理
器在空闲时，都可自己到该队列中取得一进程（或线程）来运行。在自调度方式中，可采用
在单处理机环境下所用的调度算法，如先来先服务（FCFS）调度算法、最高优先权优先（FPF)
调度算法和抢占式最高优先权优先调度算法等。
1990年，Leutenegger等人曾对在多处理机环境下的FCFS、FPF和抢占式FPF三种调
度算法进行了研究，发现在单处理机环境下，FCFS算法并不是一种好的调度算法。然而在
多处理机系统中把它用于线程调度时，FCFS算法又反而优于其它两种算法。这是因为，线
程本身是一个较小的运行单位，继其后而运行的线程不会有很大的时延，加之在系统中有
多个处理机（如N个)，这使后面的线程的等待时间又可进一步减少为1/N。FCFS算法简单、
开销小，目前已成为一种较好的自调度算法。
2）自调度方式的优点
自调度方式的主要优点表现为：首先，系统中的公共就绪队列可按照单处理机系统
中所采用的各种方式加以组织；其调度算法也可沿用单处理机系统所用的算法，亦即，
很容易将单处理机环境下的调度机制移植到多处理机系统中，故它仍然是当前多处理机
系统中较常用的调度方式。其次，只要系统中有任务，或者说只要公共就绪队列不空，
就不会出现处理机空闲的情况，也不会发生处理机忙闲不均的现象，因而有利于提高处
理机的利用率。
3）自调度方式的缺点
自调度方式的缺点不容忽视，主要表现如下：
329

--- Page 341 ---
计算机操作系统
（1）瓶颈问题。在整个系统中只设置一个就绪队列，供多个处理器共享，这些处理器
必须互斥地访问该队列，这很容易形成系统瓶颈。这在系统中处理器数目不多时，问题并
不严重；但若系统中处理器数目在数十个乃至数百个时，如果仍用单就绪队列，就会产生
严重的瓶颈问题。
(2）低效性。当线程阻塞后再重新就绪时，它将只能进入这唯一的就绪队列，但却很
少可能仍在阻塞前的处理器上运行。如果在每台处理器上都配有高速缓存（Cache），则这时
数据的拷贝。由于一个线程在其整个生命期中可能要多次更换处理器，因而使高速缓存的
使用效率很低。
（3）线程切换频繁。通常，一个应用中的多个线程都属于相互合作型的，但在采用自
调度方式时，这些线程很难同时获得处理器而同时运行，这将会使某些线程因其合作线程
未获得处理器运行而阻塞，进而被切换下来。
2.成组调度（GangScheduling）方式
为了解决在自调度方式中线程被频繁切换的问题，Leutenegger提出了成组调度方式。
该方式将一个进程中的一组线程分配到一组处理器上去执行。在成组调度时，如何为应用
程序分配处理器时间，可考虑采用以下两种方式：
1）面向所有应用程序平均分配处理器时间
每个应用程序至多可有1/M的时间去占有N个处理机。例如，有4台处理器及两个应用程
序，其中，应用程序A中有4个线程，应用程序B中有一个线程。这样，每个应用程序可
占用4台处理机一半（1/2)的时间。图10-7(a)示出了此时处理器的分配情况。由图可看出，
使用这种分配方式，在应用程序A运行时，4台处理器都在忙碌；而应用程序B运行时，
则只有1台处理器忙碌，其它3台空闲。因此，将有3/8的处理器时间（即37.5%）被浪费了。
应用程序A
应用程序B
应用程序A
应用程序B
处理器1
线程1
线程1
处理器1
线程1
线程1
空闲
处理器2
线程2
处理器2
线程2
空闲
处理器3
线程3
空闲
处理器3
线程3
空闲
处理器4
线程4
空闲
处理器4
线程4
空闲
1/2
1/2
4/5
1/5
(a)浪费37.5%
(b)浪费15%
图10-7两种分配处理机时间的方法
2）面向所有线程平均分配处理机时间
由于应用程序A中有4个线程，应用程序B中只有1个线程，因此，应为应用程序A
分配4/5的时间，只为应用程序B分配1/5的时间，如图10-7(b）所示。此时，将只有15%
的处理机时间被浪费。可见，按线程平均分配处理机时间的方法更有效。
成组调度方式的主要优点是：如果一组相互合作的进程或线程能并行执行，则可有效
地减少线（进）程阻塞情况的发生，从而可以减少线程的切换，使系统性能得到改善；此外，
330

--- Page 342 ---
第十章多处理机操作系统
因为每次调度都可以解决一组线程的处理机分配问题，因而可以显著地减少调度频率，从
而也减少了调度开销。可见，成组调度的性能优于自调度，目前已获得广泛的认可，并被
应用到许多种处理机OS中。
3.专用处理机分配（DedicatedProcessorAssigement)方式
1989年Tucker提出了专用处理机分配方式。该方式是指在一个应用程序的执行期间，
专门为该应用程序分配一组处理机，每一个线程一个处理机。这组处理机仅供该应用程序
专用，直至该应用程序完成。很明显，这会造成处理机的严重浪费。例如，有一个线程为
了和另一线程保持同步而阻塞起来时，为该线程所分配的处理机就会空闲。但把这种调度
方式用于并发程度相当高的多处理机环境，则是根据下述一些理由：
首先，在具有数十个乃至数百个处理机的高度并行的系统中，每个处理机的投资费用
在整个系统中只占很小一部分。对系统的性能和效率来说，单个处理机的利用率已远不像
在单机系统中那么重要。
其次，在一个应用程序的整个运行过程中，由于每个进程或线程专用一台处理机，因
此可以完全避免进程或线程的切换，从而大大加速了程序的运行。
Tucker在一个具有16个处理机的系统中，运行两个应用程序：一个是矩阵相乘程序，另
图10-8中示出了应用程序的加速比（Speedup）与线程数目之间的关系。当每个应用程
序中含有7～8个线程时，可获得最高加速比；当每个应用程序中的线程数大于8个时，加
正好是每个线程能分得1台处理器；当超过8个线程时，就不能保证每个线程有1台处理
器，因而会出现线程切换问题。可见，线程数愈多时切换就愈频繁，反而会使加速比下降。
因此，Tucker建议：在同时加工的应用程序中，其线程数的总和，不应超过系统中处理机
的数目。
加速比
一一一矩阵相乘
FFT
6
5
3
2
1
10
20
线程数
图10-8线程数对加速比的影响
由许多相同处理器构成的同构型多处理机系统，其处理器的分配酷似单机系统中的请
求调页式内存分配。例如，在某时刻，应把多台处理器分配给某应用程序的问题，十分类
似于将多少个内存物理块分配给某进程的问题。又如，在进行处理器分配时，又存在着一
331

--- Page 343 ---
计算机操作系统
个活动工作集的概念，它又类似于请求调页中的工作集概念。当所分配的处理器数少于活
动工作集时，将会引起线程的频繁切换，这很类似于在请求调页时，所分配的物理块数若
少于其工作集数时，便会引起页面频繁调进调出的情况。
4.动态调度
该调度方式允许进程在执行期间动态地改变其线程的数目。这样，操作系统和应用程
序能够共同地进行调度决策。操作系统负责把处理机分配给作业，而每个作业负责将分配
到的处理机再分配给自己的某一部分可运行任务。
在这种方法中，操作系统的调度责任主要限于处理机的分配，并遵循以下的原则：
（1）空闲则分配。当一个或多个作业对处理机提出请求时，如果系统中存在空闲的处
理机，就将它（们)分配给这个（些）作业，满足作业的请求。
(2）新作业绝对优先。所谓新作业，是指新到达的，还没有获得任何一个处理机的作
业。对于多个请求处理机的作业，首先是将处理机分配给新作业，如果系统内已无空闲处
（3）保持等待。如果一个作业对处理机的请求，系统的任何分配都不能满足，作业便
保持未完成状态，直到有处理机空闲，可分配予之使用，或者作业自已取消这个请求。
(4）释放即分配。当作业释放了一个(或多个)处理机时，将为这个(或这些)处理机扫描
处理机请求队列，首先为新作业分配处理机，其次按先来先服务（FCFS)原则，将剩余处理
机进行分配。
动态调度方式优于成组调度和专用处理机调度方式，但其开销之大，有可能抵消它的
一部分优势，所以在实际应用时，应精心设计具体的调度方法。
10.5.3死锁
一一
在多处理机系统中，产生死锁的原因以及对死锁的防止、避免和解除等基本方法与单
处理机相似，但难度和复杂度增加很多。尤其是在NUMA分布式环境下，进程和资源在配
置和管理上呈现了分布性，竞争资源的各个进程可能来自不同结点。但是，在每个资源结
点，通常仅记录本结点的资源使用情况，因此，来自不同结点的进程在竞争共享资源时，
对于死锁的检测显得十分困难。
1.死锁的类型
在多处理机系统中，死锁可以分成资源死锁和通信死锁。前者是因为竞争系统中可重
复使用的资源（如打印机、磁带机、存储器等）时，由于进程的推进顺序不当引起的。如集
中式系统中，如果进程A发送消息给B，进程B发送消息给C，而进程C又发送消息给
A，那么就会发生死锁。而后者，主要是在分布式系统中，由于处于不同结点中的进程，
即发生了通信死锁。
2.死锁的检测和解除
有两种检测方法：集中式检测和分布式检测。
1）集中式检测
在每台处理机上都有一张进程资源图，用于描述进程及其占有资源的状况，在负责控
332

--- Page 344 ---
第十章多处理机操作系统
制的中心处理机上，配置一张整个系统的进程资源图，并设置一个检测进程，负责整个系
统的死锁检测。当检测进程检测到环路时，就选择中止环路中的一个进程，以解决死锁。
为了及时获得最新的进程和资源状况，检测进程对各个结点更新信息的获得，可以通
过三种方式：①当资源图中加入或删除一条弧时，相应的变动消息就发送给检测进程；
②每个进程将新添加或删除的弧的信息周期性地发送给检测进程；③检测进程主动去请
求更新信息。
上述方式有个不足之处在于，由于进程发出的请求与释放资源命令的时序与执行这两
条命令的时序有可能不一致，以至于在进程资源图中形成了环形链，然而是否真的发生了
死锁，却无法判断。对此，一种合适的解决办法是：当检测进程发现这种情况后，需要再
则确认为假死锁。
2）分布式检测
分布式检测是通过系统中竞争资源的各个进程间的相互协作，实现对死锁的检测，无
需设置一个检测进程，专门用于对全局资源使用情况进行检测。该方式在每个结点中都设
排队，在一个进程对某资源操作前，必须先向所有其它进程发送请求信息，在获得这些进
程的响应信息后，才把请求资源的消息发给该资源的管理进程。每个进程都要将资源的已
分配情况通知所有进程。
由上述可见，对于分布式环境下的死锁检测，需要的通信开销较大，在实际应用中，
往往采取的是死锁预防方式。
10.6网络操作系统
计算机网络是指通过数据通信系统把地理上分散的自主计算机系统连接起来，以达到
数据通信和资源共享目的的一种计算机系统。自主计算机是指具有独立处理能力的计算机。
可见，计算机网络是在计算机技术和通信技术高度发展的基础上相结合的产物，是多个处
理机通过通信线路互连而构成的松散耦合系统，通信系统为计算机之间的数据传送提供最
重要的支持。作为多处理机系统的一种重要形式，本节将对网络操作系统作简要的介绍。
10.6.1：网络及网络体系结构
1.计算机网络的组成
计算机网络从构造的物理结构而言，是通过包括星形、树形、公用总线形、环形和网
状形等不同的拓扑结构，将地理上分散的计算机连接起来的网络。而从逻辑结构而言，计
算机网络是由三个部分组成：
（1）通信子网：由分布在不同地点的、负责数据通信处理的通信控制处理机与通信线
路互连构成，是计算机网络的基础部分，主要负责数据的传输及交换。
(2）资源子网：由负责数据处理的主计算机与终端构成，作为计算机网络中的信源和
信宿，都连接在通信子网中的一个交换设备上，构成了建立在通信子网上的资源子网，负
333