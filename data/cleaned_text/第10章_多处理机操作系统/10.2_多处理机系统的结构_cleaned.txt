(1）对称多处理器系统SMPS(SymmetricMultiprocessorSystem)。在系统中所包含的各 处理器单元，在功能和结构上都是相同的，当前的绝大多数MPS 都属于SMP系统。例如， IBM公司的SR/6000ModelF50，便是利用4片PowerPC处理器构成的。

(2）非对称多处理器系统ASMPS（AsymmetricMultiprocessorSystem)。在系统中有多种类 型的处理单元，它们的功能和结构各不相同。系统中只有一个主处理器，有多个从处理器。

110.2多处理机系统的结构 在采用共享存储器方式的多处理机系统中，若干个处理器可以共享访问一个公用的 RAM，而这个RAM可以由多个不同的存储器模块组成。系统为运行在任何一个CPU上的 程序提供了一个完整的虚拟地址空间视图。每个存储器地址单元均可被所有的CPU进行读 写。对于这个性质，一方面可以方便地利用存储器单元实现处理机之间的通信；另一方面 也必须在进程同步、资源管理及调度上，做出有别于单处理机系统的特殊处理。但是，由 于程序或进程对不同存储器模块的读写速度可能存在的差异，形成了不同的多处理机体系 结构：UMA多处理机结构和NUMA多处理机结构。

10.2.1UMA多处理机系统的结构 一一 一一一 所谓UMA(UniformMemoryAccess)，即统一内存访问（也称一致性内存访问)。在这种 结构的多处理机系统中，各处理器单元（CPU)在功能和结构上都是相同的，在处理上没有主 从之分（即属于SMP系统），每个处理机可以访问不同模块中的存储器单元，并且对于每个 存储器单元的读写速度是相同的。实际上，根据处理机与存储器模块的连接方式的不同， 可以具体分为以下三种结构：

1.基于单总线的SMP结构 如图10-1(a)所示，在这种结构的系统中，把多个处理器与一个集中的存储器相连，所 有处理器都通过公用总线访问同一个系统的物理存储器，每个处理机可以访问不同存储器 模块中的单元，以及与其它处理机进行通信。这就意味着该系统只需要运行操作系统的一 个拷贝，因此，为单处理器系统编写的应用程序可以直接移植到这种系统中运行。实际上， 这种结构的SMP系统也被称为均匀存储器系统，即对于所有处理器来说，访问存储器中的 任何地址所需的时间都是一致的。 例如，当处理机需要读取某个存储器模块单元的内容（即一个存储器字）时，首先检查 总线的忙闲状态。如果空闲，CPU便将所要访问的存储器地址放到总线上，并插入若干控 制信号，然后等待存储器将所需的存储器字放到总线上；否则，如果总线状态为忙，则CPU 进行等待，直到总线空闲。 显然，这种结构的缺点在于可伸缩性有限。系统中所有CPU对存储器的访问，都需要 通过总线进行。多个CPU可能同时需要对总线进行访问，形成了对总线资源的争夺。随着 CPU数目的增加，由于总线资源的瓶颈效应，对此进行相关协调和管理的难度急剧增加， 从而限制了系统中CPU的数目。一般而言，在这种系统中，CPU的数目在4至20个之间。 对上述的问题，可以通过为每个CPU配置一个高速缓存的方法解决。如图10-1(b)所 309  计算机操作系统 示，这些高速缓存可以通过在CPU内部、处理机板、CPU附近等多种方式设置。这样，可 以把每个CPU常用的或者即将用到的数据存放在其本地的高速缓存中，可以很大程度地减 少该CPU对总线的访问频率，极大地减少总线上的数据流量，以支持更多的CPU。应该注 意的是，在这里，高速缓存的交换和存储是以32字节或64字节块为单位，而不是单个字 节。系统中高速缓存可以为所有CPU所共享，也可以为每一个CPU所独立拥有。 私有存储器 共享存储器 共享存储器 共享存储器 CPU CPU CPU CPU M M M 总线 总线 高速缓存 (a)没有高速缓存 (b)有高速缓存 (c)有高速缓存和私有存储器 图10-1基于总线的SMP结构

2.使用多层总线的SMP结构 对于单总线结构中存在的总线瓶颈问题的另一个解决方法，就是使用多层总线结构。 在这种结构中，系统中所有的CPU不仅共享一个高速缓存，还有一个本地私有的存储器， 如图10-1(c)所示。各CPU与本地的私有存储器、IO设备通过本地总线连接，系统再使用 系统总线将不同CPU的本地总线进行连接，并且将系统中的共享存储器连接在系统总线 上。系统总线一般在通信主板中实现，各CPU使用本地总线访问其本地私有存储器，而通 过系统总线访问共享存储器。 地把所运行程序的正文、字符串、常量和其它只读数据存放在其私有存储器中，仅将共享 变量存放在共享存储器中。这种结构可以很大程度地减少各CPU对系统总线的占用，因而 可以在相当程度上减少系统总线上的流量，使系统可以支持更多的CPU(16～32个)。 但是，这种方式提高了对程序编译器的要求，而为了尽可能减少使用总线的频率，就 需要对程序中的数据进行仔细的安排，显然这也增加了编程的难度。

3.使用单级交叉开关的系统结构 在这种结构中，利用电话交换系统中使用交叉开关（crossbarswitch)的方法，如图10-2 所示，将系统中所有的CPU与存储器结点，通过交叉开关阵列相互连接。每个交叉开关均 之间因为要访问存储器模块所形成的对链路的争夺。而且，在任意两个结点(CPU与CPU) 之间也都能找到一个交叉开关，在它们之间建立专用连接通路，方便CPU之间的通信。 交叉开关的状态可根据程序的要求，动态地设置为“开”和“关”。例如图10-2(a)中 的三个小黑点，表示有三个交叉开关闭合，即允许(CPU，存储器)对(010,110)、（101,101)、 (110,010)同时连接。 310  第十章 多处理机操作系统 交叉点开关打开 000 001 010 011 (b) 100 101 交叉点开关关闭 关闭的交叉点开关 打开的交叉点开关 (a) (c) 图10-2使用交叉开关的UMA多处理机系统 使用交叉开关的UMA多处理机系统具有如下特征：

（1）结点之间的连接：交叉开关一般是构成一个N×N的阵列，但在每一行和每一列 中，都同时只能有一个交叉点开关处于“开”状态，从而它同时只能接通N对结点。

(2）CPU结点与存储器之间的连接：每个存储器模块同时只允许一个CPU结点访问， 故每一列只能接通一个交叉点开关，但是为了支持并行存储访问，每一行同时可以接通多 个交叉开关。

(3）交叉开关的成本为N²，N为端口数，限制了它在大规模系统中的应用，如1000个 CPU与1000个存储器模块连接，就需要1百万个交叉点，这在现实中是不可行的。一般 只适合于8～16个处理器的中等规模系统。

4.使用多级交换网络的系统结构 图10-3(a)是一个最简单的2×2交叉开关，它有两个输入和两个输出。送入任一输入的 CPU 3级 存储器 000 000 1A 2A 001 001 010 010 B 2B 3B 011 011 100 100 1C 2C 3C 101 101 110 110 111 (a)一个2×2的交换机 (b)使用多级交换开关的结构 图10-3使用多级交换网络的SMP结构示意图 311  计算机操作系统 信息可以交换到任一输出线上。可以将这样的多级小交换开关分级连接起来，形成多级交 叉开关网络，如图10-3(b)所示，图中的1A、2A、“、1B、“、3C等都是一个交叉开关级， 在相邻级别的交叉开关之间设置固定的物理连接。处理机和存储器模块分别位于网络的两侧， 每台处理机通过网络访问存储器模块，而且所有处理机的访问方式都是一样的，机会均等。 在这种结构中，由于对每个CPU都提供了多条到每个存储器模块的路径，因而减少了 阻塞概率，很好地分散了流量，提高了访问速度。其缺点在于，硬件结构昂贵，且系统中 处理机数目也不适合过多，一般在100个以下。 如前所述，以上四种SMP体系结构的多处理机系统具有一个共同的特征，就是共享， 每一个处理机对系统中所有资源(内存、IO等)都是共享的。也正是由于这种特征，决定了 这种结构的扩展能力非常有限：每一个共享的环节都可能造成处理机扩展时的瓶颈：对处 理机而言，最受限制的是内存，每个CPU必须通过公用的总线（或连接路径)，访问相同（或 彼此)的内存资源。随着CPU数量的增加，公用总线(或连接路径）的流量急剧增加，形成超 载，致使内存访问冲突将迅速增加，并成为制约提高系统性能的瓶颈，造成CPU资源的浪 费，很大程度地降低了CPU性能的有效性。 由于SMP在这种扩展能力上的限制，人们开始探究如何进行有效的扩展，才能构建大 型系统的技术，NUMA就是这种探究的成果之一。利用NUMA技术，可以把几十个CPU（甚 至上百个CPU)组合在一个服务器内。

10.2.2NUMA多处理机系统结构

1.NUMA结构和特点 所谓NUMA(Nonuniform-Memory-Access)，即非统一内存访问（也称非一致存储访问)。在 这种结构的多处理机系统中，其访问时间随存储字的位置不同而变化，系统中的公共存储期 和分布在所有处理机的本地存储器共同构成了系统的全局地址空间，可被所有的处理机访问。 如图10-4所示，NUMA拥有多个处理机模块（也称为节点），各节点之间通过一条公用总 节点0 节点256 cpul cpu4 cpul cpu4 局部总线 局部总线 高速缓存 高速缓存 目录 群内共享 目录 群内共享 存储器 ！存储器 互连网络或公用总线 图10-4NUMA结构的多处理机系统 312  第十章多处理机操作系统 线或互连模块进行连接和信息交互。每个节点又可以由多个处理机(CPU)组成，如四个奔腾微 处理器，它们分别拥有各自独立的本地存储器、IO槽口等，并通过一条局部总线与一个单独 的主板上的共享存储器（也称群内共享存储器）连接。这样一个系统一般可以包含16到256个 CPU。由此可见，因为通过互连网络会产生附加延迟，处理机访问本地存储器是最快的，但 访问属于另一台处理机的远程存储器则比较慢。所有机器都有同等访问公共存储器（也称全局 存储器）的权利，但是访问群内存储器的时间要比访问公共存储器短。对于机群间存储器的访 问权，也可用不同的方法描述。伊得诺依大学研制的Cedar多处理机就使用这种结构。 NUMA结构的特点是：所有共享存储器在物理上是分布式的，在逻辑上是连续的，所 有这些存储器的集合就是全局地址空间，系统中的每一个CPU都可以访问整个系统的内 存，但访问时所使用的指令却不同；因此，在NUMA中，存储器一般分为三层：①）本地 存储器；②群内共享存储器：③全局共享存储器或其它节点存储器。显然，每一个CPU 访问本地存储器的速度远远高于访问全局共享存储器或远程访问其它节点存储器（远地内 存）的速度。 对一个运行在NUMA多处理机系统中的应用程序而言，系统提供了一个地址连续的、 完整的内存空间，但当一个处理器在特定内存地址寻找数据的时候，可能需要访问三层（级） 存储器：首先察看CPU的本地存储器，其次是本节点的共享存储器，最后是其它节点的“远 程内存”（或全局共享存储器）。可见，为了更好地发挥系统性能，开发应用程序时，应注 意尽量减少不同节点之间的信息交互。 对于NUMA多处理机结构，为了减少CPU对远程内存的访问，还可以通过为每个CPU 再配备各自的高速缓存的方法实现，这样的结构称为CC-NUMA。与此对应的，将每个CPU 没有配备各自的高速缓存的结构称为NC-NUMA。

2.CC-NUMA构造方法 目前，对于构造大型的CC-NUMA多处理机系统，最常用的方法是采用基于目录的多 处理机。其基本思想是：对于系统中每一个CPU所拥有的若干高速缓存单元，都以一定数 量的单元为一组，构成一个高速缓存块，为每个CPU配置一张高速缓存块目录表（下简称 目录表)，对每一个高速缓存块的位置和状态进行记录和维护。每个CPU的每条访问存储 器单元的指令都必须首先查询这张表，从中判断该存储器单元是否在目录表中，即其内容 读取高速缓存内容、变换高速缓存块节点，修改目录表等。下面将用一个简单的例子加以 具体的阐述。 例如，在一个拥有256个节点的NUMA多处理机系统中，每个节点可以包含若干个 CPU（1到4个），每个CPU通过局部总线和一个16MB的RAM相连接，节点间通过互连 网络连接，其中节点1包含0～16MB，节点2包含16～32MB，“，以此类推，系统整 个存储器空间包含了16M×256=224×2°=232个字节。其中，由于一个节点中有四个CPU 共享16MB的本地存储器，因此该存储器被划分为四个部分，分别提供给四个CPU作为 其本地存储器，即每个CPU拥有4MB空间(22)，其中CPU1包含0～4MB，CPU2包含4~ 8MB，·….…….，以此类推。 考虑到每一个CPU都拥有一张目录表，其中的每一个表项应记录一个本地高速缓存块 地址，该高速缓存块中的每一个高速缓存单元内容，是本地某个存储器单元内容的拷贝。 313  计算机操作系统 因此，对于32位机而言，比较合适的方法是采用16位的表项长度，将存储器空间划分为若 干个长度为64字节(222/216=2°)的存储器单元组，对应地，也将高速缓存中64个字节为一组 为使描述简单起见，下面只考虑每个节点中只有一个CPU的情况，如图10-5(a)所示。 当CPU20（即20号节点的CPU)发出一条远程存储器单元访问指令后，由操作系统（中的 MMU)将地址翻译成物理地址，并拆分为三个部分，如图10-5(b)所示，节点号36，第4块， 块内偏移量8，即访问的存储器不是20号节点的，而是36号节点。然后，MMU将请求消 息通过互连网络发送给节点36，并询问第4块是否已在高速缓存中，如果是，则请求高速 缓存的地址。 36号节点接收到请求后，通过硬件检索其本地目录表的第4项，如图10-5（c）所示，该 项内容为空，即要访问的存储器块内容没有进入高速缓存。通过硬件将36号节点本地RAM 中的第4块内容传送到20号节点，并将本地目录中第4项内容进行更新，指向20节点， 表示该存储块内容进入了20号节点的高速缓存。 节点0 节点1 节点256 CPU CPU CPU 存储器 存储器 存储器 目录 目录 目 局部总线 局部总线 局部总线 互连网络 (a)基于目录256节点的多处理机 218-1 ： 8 18 6 0 节点 块 偏移量 0 1 82 0 0 (b)32位存储器地址分为三个域 (c)位于36字节的目录 图10-5-CC-NUMA构造方法 现在，再考虑第二种情况。CPU20发出的请求是节点36的第2项，如图10-5（c）所示， 36号节点接收到该请求后，发现该项内容为82，即要访问的存储器块内容已经进入82号 节点的高速缓存，于是更改本地目录中的第2项内容，将其指向20号节点，然后发送一条 消息到82号节点。82号节点接收到消息后，从其高速缓存第2块中取出内容发送回20号 节点，并同时修改本地目录中第2项内容，将其指向20号节点，并将相应高速缓存块中的 内容作废。20号节点接收到82号节点返回的内容后，存入本地高速缓存的第2块，修改 本地目录的第2项，将其指向本地高速缓存第2块。 从上述过程可以看出，在这种NUMA结构的多处理机系统中，仍然需要通过大量的消 息传递的方法实现存储器共享。同时，由于每个存储块只能进入一个节点的高速缓存，因 而限制了对存储器访问速度的提高。 因此，NUMA技术的主要问题是：远程内存访问由于访问远地内存的延时远远超过本 地内存，因此当CPU数量增加时，系统性能无法线性增加。 314  第十章多处理机操作系统

1710.3多处理机操作系统的特征与分类

10.3.1多处理机操作系统的特征 一 多处理机操作系统是在单机多道程序系统的基础上发展起来的，它们之间有许多相似 之处，但也存在着较大的差异。归纳起来，多处理机操作系统具有以下几方面的新特征：

1.并行性 单机多道程序系统的主要目标是，为用户建立多个虚拟处理机以及模拟多处理机环境， 使程序能并发执行，从而改善资源利用率并提高系统的吞吐量。而在多处理机系统中，由 于存在着多个实处理机，已经可使多个进程并行执行，因此，多处理机操作系统的主要目 标应是进一步增强程序执行的并行性程度，以获得更高的系统吞吐量及提高系统的运算速 度。实际上，在多处理机系统中，每个实处理机仍然可以通过多道程序技术，虚拟为若干 个虚拟处理机，使多个进程在一个实处理机上并发执行。因此，在多处理机系统中，多个 进程之间存在着并行执行和并发执行两种关系。 对于开拓硬件操作的并行性及程序执行的并行性，始终是多处理机系统的中心问题。 前者主要依赖于系统结构的改进，后者则是操作系统的主要目标和任务。为了描述任务的 并行性，控制它们的并行执行，还应该配置相应的并行程序语言，以便在一个任务开始时， 能够派生出与之并行执行的新任务。对于程序执行并行性的开拓，必然导致处理机管理及 存储器管理等功能在实现上的复杂化。

2.分布性 在单处理机系统中，所有的任务都是在同一台处理机上执行的，所有的文件和资源也 都处于操作系统的统一管理之下。然而对于多处理机系统而言，无论其结构如何，在任务、 资源和对它们的控制等方面，都呈现出一定的分布性。这种情况，在松散耦合系统中表现 尤其明显：

（2）资源的分布：各处理机都可能拥有属于自己的本地资源，包括存储器、IO设备等， 对这些资源的使用可以是私有方式，也可以是提供给其它处理机的共享方式；

（3）控制的分布，在系统的每个处理单元上，都可能配置有自己的操作系统，用于控 制本地进程的运行和管理本地资源，以及协调各处理机之间的通信和资源共享。

3.机间的通信和同步性 在多处理机系统中，不仅在同一处理机上并发执行的诸进程之间，由于资源共享和相 互合作的需要，须实现同步和通信，而且在不同处理机上运行的不同进程之间，也需要进 行同步和通信，除了它们之间也需要资源共享和相互合作外，这对于提高程序执行的并行 性、改善系统的性能至关重要。但在多处理机系统中，不同处理机之间的同步和通信，其 实现机制远比单处理机系统要复杂的多，因而成为多处理机操作系统中最重要的问题之一。 315