会因为都要对一些公用表格进行访问而发生冲突，因此系统中还是需要设置冲突仲裁机构。

（4）存储空间开销大。一般地，这类操作系统适用于松散耦合型多处理机系统，由于 每个处理机均有一个本地（局部)存储器，用来存放管理程序副本，即每台处理机中都驻留了 操作系统内核，占用了大量的存储空间，造成较多的存储余，致使存储空间利用率不高。

（5）处理机负载不平衡。由于不能像主一从式系统中那样，由一个主处理机统一负责 整个系统的管理和调度，因而要实现处理机负载平衡非常困难。

3.浮动监督式（floatingsupervisorControlMode) 浮动监督式，也称为浮动管理程序控制方式，这是最复杂的，但也是最有效、最灵活 的一种多处理机操作系统方式，常用于紧密耦合式的对称多处理机系统中。在这种方式实 现的系统中，所有的处理机组成一个处理机池，每台处理机都可对整个系统中的任何一台 IVO设备进行控制，以及对任何一个存储器模块进行访问，这些处理机由操作系统统一进行 管理，在某段时间内可以指定任何一台（或多台）处理机作为系统的控制处理机，即所谓“主” 处理机（或组），由它（或它们)运行操作系统程序，负责全面管理功能，但根据需要，“主” 处理机是可以浮动的，即从一台处理机切换到另一台处理机。采用这种操作系统方式的多 处理机系统有IBM3081上运行的MVS，VM以及C·mmp上运行的Hydra等。 浮动监督式操作系统具有如下的优缺点：

（1）高灵活性。由于对于系统内所有的处理机采用的是处理机池管理方式，其中每一 台处理机都可用于控制任一台I/O设备和访问任一存储块，因此大多数任务可在任何一台 处理机上运行，使系统的灵活性相当强。

(2）高可靠性。在上述三种操作系统中，浮动监督式操作系统具有最好的可靠性。因 为，系统中任何一台(从)处理机的失效，不过是处理机池中减少了一台可供分配的处理机 而已；而如果是“主”处理机失效，也只需将操作系统浮动（切换）到另一台处理机上运行， 从而保证系统仍能继续正常运行下去。

(3）负责均衡。在这样的系统中，一方面由于大多数任务可以在任何一台处理机上运 行，另一方面也因为在系统中设置了一台（或多台）“主”处理机，对整个系统的资源和调 度进行了统一的管理，因此可以根据各处理机的忙闲情况，将任务均匀分配到各处理机上 执行，尤其是可以将一些非专门的操作（如IO中断)，分配给那些在特定时段内最不忙的处 理机去执行，使系统的负载达到较好的平衡。

(4）实现复杂。一方面，由于对存储器模块和系统表格访问冲突的不可避免，需要配 置功能较强的冲突仲裁机构，包括硬件和软件两方面。例如，多个处理机同时访问同一存 储器模块时，可采用硬件解决；而对系统表格的冲突访问，则可采用静态或动态优先级策略； “主”处理机，即可以同时执行同一个管理服务子程序，因此，要求管理程序具有可重入性。

10.4进程同步 在多处理机系统中，进程间的同步显得更加重要和复杂。在紧密耦合多处理机中，多 个处理机是共享存储的，因此各处理机上的诸进程之间可通过该共享存储来实现同步，进 319  计算机操作系统 程间的同步实现相对也比较简单。但对于松散耦合的多处理机，进程之间的同步可能采取 的方式较多且复杂，可分为集中式和分布式两大类同步方式。

10.4.1集中式与分布式同步方式

1.中心同步实体 为实现进程之间的同步，系统中必须有相应的同步实体(SynchronizingEntity)，如硬件 锁、信号量以及进程等。如果该同步实体满足下述两个条件，则称之为中心同步实体：

（1）具有唯一的名字，并且为彼此必须同步的所有进程所知道。 立即选择一个新的中心同步实体投入运行。

2.集中式同步机构 基于中心同步实体所构成的所有同步机构被称为集中式同步机构。相应的，其它同步 机构则称为非集中式同步机构。在单处理机系统中，为了同步多个进程对共享数据的访问， 内核采用了一些同步机制，如硬件锁、信号量等。而对于多处理机系统而言，同样是为实 并发进程进行同步，还需对不同处理器上的进程进行同步，以保证多处理机系统能有条不 紊地运行。为此，在多处理机系统中，又增加了一些如自旋锁、RCU锁、时间邮戳、事件 计数以及中心进程等多种同步机制。

3.集中式与分布式同步算法 在多处理机系统中，为实现进程同步，往往还需要有相应的同步算法支持同步机构， 一般分为以下两种：

（1）集中式同步算法。集中式同步算法具有两个特征：①对于多个进程需要同时访问 共享资源或进行通信时，仅由中心控制结点做出判定，选择一个进程执行；②判定所需要 的全部信息都集中在中心控制结点。集中式同步算法的缺点在于：①可靠性差，由于中心 控制结点的故障，会对系统造成灾难性的影响，对此，有的系统充许中心控制结点进行浮 大量的资源共享和进程通信都是通过中心控制结点进行管理的，很容易使中心控制结点成 为整个系统的瓶颈，严重影响到系统的响应速度和吞吐量。

(2）分布式同步算法。一个完全分布式同步算法具有以下特征：①所有结点具有相同 的信息；②所有结点仅基于本地信息做出判断：③为了做出最后的判定，所有的结点担 负相同的职责；④为了做出最后的判定，所有的结点要付出同样的工作量；5通常一个 结点发生故障，不会导致整个系统的崩溃。事实上，完全分布式算法的应用很少，大多数 同步算法都无法同时满足上述五点要求。

4.中心进程方式 该方式是在系统中设置一个中心进程(或称为协调进程)，该进程保存了所有用户的存 取权限、冲突图(conflict graph)等信息。每一个要求访问共享资源的进程，都先向中心进程 发送一条请求消息，中心进程收到该请求后，便去查看冲突图，如果该请求不会引起死锁， 320  第十章多处理机操作系统 便将该请求插入请求队列，否则退回该请求（rollback)。当轮到该请求使用共享资源时，中 心进程便向请求进程发送一条回答消息，然后请求进程即可进入自己的临界区，访问共享 资源。请求进程在退出临界区后，还需要向中心进程发送一条释放资源的消息，中心进程 接收到该消息后，又可向下一个请求进程发送回答消息，允许它进入其临界区。在这种同 步方式中，任何一个进程要进入其临界区，都需要请求、回答、释放三个消息。为了提高 系统的可靠性，中心进程应可以浮动。 在单处理机系统和共享存储器的多处理机系统中，基本上都是采用集中式同步方式。 而在分布式系统中，则都是采用分布式同步方式。对于松散耦合式多处理机系统（包括计算 机网络），则一部分采用集中式，另一部分采用分布式。本节只对几种常用的同步机构和算 法进行介绍。

10.4.2自旋锁（spinlock）

1.自旋锁的引入 如前所述，在单CPU系统中，CPU在执行读一修改一写原语操作时，是具有原子性 的，即在执行这些操作时不会被中断。保证原子性的基本方法是，在执行原语之前关中断， 完成后再开中断。但是，在对称多处理机系统中，CPU在执行读一修改一写原语时，已不 能再保证其操作的原子性。因为CPU所执行的读一修改一写原语操作通常都包含了若干条 享，它们是通过竞争来获取总线的。如果某CPU在执行原语的过程中由其它CPU争得了 总线，就可能会导致该CPU与其它CPU对同一存储单元读一写操作的交叉，造成混乱。 因此，在多处理机系统中，还必须引入对总线实现互斥的机制。于是，自旋锁机制也就应运 而生，并已大量应用于对总线资源的竞争。当然，自旋锁机制并不局限于对总线资源的竞争。

2.实现对总线互斥访问的方法 利用自旋锁实现对总线互斥访问的方法是：在总线上设置一个自旋锁，该锁最多只能 被一个内核进程持有。当一个内核进程需要使用总线，对某个存储单元进行读写访问时， 先请求自旋锁，以获得对总线的使用权。如果该锁被占用，那么这个进程就会一直进行“旋 转”，循环测试锁的状态，直到自旋锁重新可用。如果锁未被占用，请求该锁的内核进程便 能立刻得到它，并且继续执行，直到完成对指定存储单元的读写操作后，释放该锁。可见， 自旋锁可以在任何时刻防止多个内核进程同时进入临界区，因此可有效地避免多处理机上 并发运行的内核进程对总线资源的竞争。

3.自旋锁与信号量的主要差别 自旋锁与信号量的主要差别在于：自旋锁可避免调用进程阻塞。由于自旋锁使用者一 般保持锁时间非常短，调用进程用“旋转”来取代进程切换。而我们知道进程切换需要花 费一定开销，并且会使高速缓存失效，直接影响系统的性能，因此将自旋锁应用于对总线 资源的竞争，其效率远高于信号量机制，且在多处理器环境中非常方便。 显然，用自旋锁所保护的临界区一般都应比较短，否则，发出请求的多个CPU在锁被 占用时，就会因为都只是对锁进行循环测试，即忙等，浪费过多的CPU资源。 一般而言，如果对于被保护的共享资源仅在进程的上下文访问，或有共享设备，或调 321  计算机操作系统 用进程所保护的临界区较大时，应使用信号量进行保护。但是如果被保护的共享资源需要 中断上下文访问，或调用进程所保护的临界区非常小，即对共享资源的访问时间非常短的 情况下，就应使用自旋锁。自旋锁保持期间是不可抢占的，而信号量和读写信号量保持期 间是可以被抢占的。自旋锁只有在内核可抢占或SMP的情况下才真正需要，在单CPU且 不可抢占的内核下，为防止中断处理中的并发操作，可简单采用关闭中断的方式，不需要 自旋锁，此时自旋锁的所有操作都是空操作。

4.自旋锁的类型 使用自旋锁的基本形式为： spin_lock(&lock); /*临界区代码；*/ .·... spin_unlock(&lock); 常用的自旋锁有三种类型：普通自旋锁、读写自旋锁和大读者自旋锁。

（1）普通自旋锁：若是锁可用，则将自旋锁变量置为0，否则为1。该类自旋锁的使用 不会影响当前处理机的中断状态，一般在临界区的代码在禁止中断情况下使用，或者不能 被中断处理程序所执行。

(2）读写自旋锁：允许多个读者同时以只读的方式访问相同的共享数据结构，但是当一个 写者正在更新这个数据结构时，不允许其它读者或写者访问。该类自旋锁较普通自旋锁充许更 数和一个解锁标记。一般而言，在写者等待的情况下，新进的读者较写者更容易抢占该锁。

（3）大读者自旋锁：获取读锁时只需要对本地读锁进行加锁，开销很小：获取写锁时 则必须锁住所有CPU上的读锁，代价较高。

10.4.3读一拷贝一修改锁和二进制指数补偿算法

1.读一拷贝一修改锁（RCU）的引I入 不论是第二章中的读写问题，还是前面所介绍的读写自旋锁，都是允许多个进程同时 读，但只要有一个写进程在写，便禁止所有读进程去读，使读者进入阻塞状态。如果写的 时间非常长，将严重影响到多个读进程的工作。是否能改善这一情况呢？即使有写进程在 写，读进程仍可以去读，不会引起读进程的阻塞。回答是肯定的，其解决方法是改变写进 程对文件(共享数据结构)进行修改（写）的方式。此即，当某写进程要往某文件中写入数据时， 它先读该文件，将文件的内容拷贝到一个副本上，以后只对副本上的内容进行修改。修改 完成后，在适当时侯再将修改完后的文件全部写回去。

2.RCU（Read-Copy-Update)锁 RCU锁用来解决读者一写者问题。对于被RCU保护的共享文件(数据结构)，无论读者 和写者，都是以读的方式对其进行访问的，对于读者而言，不需要获得任何锁就可以访问 它，对于写者而言，在访问它时，先制作该文件的一个副本，只对副本上的内容进行修改， 然后使用一个回调（callback)机制，即向系统中一个称为垃圾收集器的机构注册一个回调函 数。最后，在适当的时机，由垃圾收集器调用写者注册的回调函数，把指向原来数据的指 针重新指向新的被修改的数据，完成最后的数据释放或修改操作。 322 

3.写回时机 在RCU锁机构中，如何确定将修改后的内容写回的时机？显然，最好是在所有读者都 已完成自已的读任务后再将修改后的文件写回。为此，每一个读者完成对共享文件的操作 后，都必须向写者提供一个信号，表示它不再使用该数据结构。当所有的读者都已经发送 信号之时，便是所有引I用该共享文件的CPU都已退出对该共享数据的操作之时，也就是写 者可以将修改后的文件写回之时。对于写者而言，从对副本修改完成后，到执行真正的写 修改，中间有一段延迟时间，称为写延迟期（graceperiod)。

4.RCU锁的优点 RCU实际上是一种改进的读写自旋锁。它的主要优点表现为如下两方面：

（1）读者不会被阻塞。读者在访问被RCU保护的共享数据时不会被阻塞。这一方面极 大地提高了读进程的运行效率，另一方面也使读者所在的CPU不会发生上下文切换，减少 了处理机的开销。 个写者同时访问被保护的数据，无需为共享数据设置同步机构，因而读者没有什么同步开 销，也不需要考虑死锁等问题。但是写者的同步开销却比较大，需要复制被修改的数据结 构，延迟数据结构的释放，还必须使用某种锁机制，与其它写者的修改操作同步并行。 操作较多，而写操作很少，用RCU的确是利大于弊；反之，如果写比较多，对读者的性能 提高可能不足以弥补给写者带来的损失，此时还是应当采用读写自旋锁。

10.4.4二进制指数补偿算法和待锁CPU等待队列机构 一

1.二进制指数补偿算法 多个CPU在对共享数据结构互斥访问时，如果该数据结构已被占用，就需要不断地对 锁进行测试，造成总线流量的增大。二进制指数补偿算法的基本思想是：为每一个CPU对 锁进行测试的TSL指令设置一个指令延迟执行时间，使该指令的下次执行是在该延迟执行 时间设定的时间后进行，其延迟时间是按照一个TSL指令执行周期的二进制指数方式增加。 例如当一个CPU发出TSL指令对锁进行第一次测试，发现锁不空闲时，便推迟第二次测 试指令的执行时间，等到2个指令执行周期后，如果第二次测试仍未成功，则将第三次测 试指令的执行时间推迟到22个指令执行周期后，·…，如果第n-1次测试仍未成功，则 将第n次的测试推迟到2-个指令执行周期后，直到一个设定的最大值；当锁释放时，可 能首先由延迟时间最小的CPU获得该锁。 采用二进制指数补偿算法可以明显降低总线上的数据流量。这是因为，一方面，可以 将短时间内各CPU对锁的需求，在时间上进行不同程度的延迟，增加测试的成功率，减少 各CPU对锁的测试次数；另一方面，在锁不空闲时，也很大程度地减少各CPU对其进行 测试的频率。但是，该算法的缺点在于，锁被释放时，可能由于各CPU的测试指令的延迟

2.待锁CPU等待队列机构 如何及时发现锁空闲，另一种同步机构一一锁等待队列机构很好地解决了这一问题。 323  计算机操作系统 这种机构的核心思想是：为每一个CPU配置一个用于测试的私有锁变量和一个记录待锁 CPU的待锁清单，存放在其私有的高速缓存中。当多个CPU需要互斥访问某个共享数据结 构时，如果该结构已被占用，则为第一个未获得锁的CPU分配一个锁变量，并且将之附在 占用该共享数据结构CPU的待锁清单末尾：再为第二个未获得锁的CPU也分配一个锁变 量，并且将之附在待锁清单中第一个待锁CPU的后面；·….."；为第n个未获得锁的CPU 分配一个其私有的锁变量，并且将之附在待锁清单中第n-1个CPU的后面，形成一个待 锁CPU等待队列。当共享数据结构的占有者CPU退出临界区时，从其私有的高速缓存中 查找待锁清单，并释放第一个CPU的私有锁变量，允许它进入临界区，第一个CPU操作 完成后，也对其锁变量和第二个待锁CPU的锁变量进行释放，让第二个CPU进入其临界 区，依此类推，直至第n个待锁CPU进入其临界区。 在整个过程中，每一个待锁CPU都仅是在自己的高速缓存中，对其私有的锁变量进行 不断的测试，不会对总线进行访问，减少了总线的流量。同时，一旦锁空闲，便由释放该 锁的CPU通过修改其待锁清单中的下一个待锁CPU的锁变量的方法，及时通知下一个待 锁CPU进入临界区，从而避免了资源空闲而造成的浪费。

10.4.5定序机构 在多处理机系统和分布式系统中，有着许多的处理机或计算机系统，每个系统中都有 自己的物理时钟。为了能对各系统中的所有特定事件进行排序，以保证各处理机上的进程 能协调运行，在系统中应有定序机构。

1.时间邮戳定序机构（TimestampOrderingMechanism） 对时间邮戳定序机构最基本的要求是，在系统中应具有唯一的、由单一物理时钟驱动 的物理时钟体系，确保各处理机时钟间的严格同步。该定序机构的基本功能是：

（1）对所有的特殊事件，如资源请求、通信等，加印上时间邮戳；

（2）对每一种特殊事件，只能使用唯一的时间邮戳；

(3）根据事件上的时间邮戳，定义所有事件的全序。 利用时间邮戳定序机构，再配以相应的算法，可实现不同处理机的进程同步。实际上， 许多集中式和分布式同步方式，都是以时间邮戳定序机构作为同步机构的基础。

2.事件计数（EventCounts）同步机构 在这种同步机构中，使用了一个称为定序器（Sequencers)的整型量，为所有特定事件进 行排序。定序器的初值为O，且为非减少的，对其仅能施加ticket(S）操作。当一个事件发生 操作形成了一个非负的、增加的整数序列，然后把打上标号的事件送至等待服务队列排队。 与此同时，系统将所有已服务事件的标号保留，并形成一个称为事件计数E的栈。实际上， E是保存已出现的某特定类型事件编号计数的对象（Object)，其初值为0，当前值是栈顶的 标号。对于事件计数，有下面三种操作： 1)await(E，V) 每当进程要进入临界区之前，先执行await操作，如果E<V，将执行进程插入到EQ 队列，并重新调度；否则进程继续执行。await可定义如下： 324  第十章多处理机操作系统 await(E,V) { if(E<V){ i=EP; stopO; i->status="block"; i->sdata=EQ; insert(EQ,i); schedulerO; else continue; 1 2) advance(E) 每当进程退出临界区时，应执行advance(E)操作，使E值增1。如果EQ队列不空，则 进一步检查队首进程的V值；若E=V，则唤醒该进程。advance(E)操作可描述如下： advance(eventcountE){ E=E+1; if (EQ<>NIL) { V=inspect(EQ,1); if (E==V) wakeup(EQ,1); 1 一个进程执行临界区的操作序列为： await(E,V); Accessthecriticalresources; advance(E); 3) read(E) 返回E的当前值，提供给进程参考，以决定是否要转去处理其它事件。如果设计得当， 允许await、read和advance这三个操作，在同一事件上并发执行，但对定序器必须互斥使用。

10.4.6面包房算法 → 该算法是最早的分布式进程同步算法，是利用事件排序的方法对要求访问临界资源的 全部事件进行排序，按照FCFS次序对事件进行处理。该算法可以非常直观地类比为顾客 去面包店采购：面包店只能接待一位顾客，已知有n位顾客要进入面包店，安排他们按照 次序在前台登记一个签到号码，签到号码逐次加1；顾客根据签到号码由小到大的顺序， 依次入店购买；完成购买的顾客在前台把其签到号码归0。如果完成购买的顾客需再次进 店购买，必须重新排队。该算法的基本假定如下：

（1）系统由N个结点组成，每个结点只有一个进程，仅负责控制一种临界资源，并处 理那些同时到达的请求。

(2）每个进程保持一个队列，用来记录本结点最近收到的消息，以及本结点自已产生 325  计算机操作系统 的消息。

(3）消息分为请求消息、应答消息和撤销消息三种，每个进程队列中的请求消息根据 事件时序排序，队列初始为空。

(4）进程Pi发送的请求消息形如request(Ti，i)，其中 Ti=Ci，是进程Pi发送此消息时 对应的逻辑时钟值，i代表消息内容。 面包房算法描述如下：

(1）当进程Pi请求资源时，它把请求消息request(Ti,i)排在自己的请求队列中，同时也 把该消息发送给系统中的其它进程；

(2）当进程Pj接收到外来消息request(Ti,i)后，发送回答消息reply(Tj,j)，并把request(Ti,i) 放入自己的请求队列。应当说明，若进程Pj在收到request(Ti，i)前已提出过对同一资源的 访问请求，那么其时间戳应比（Ti，i)小。

(3）若满足下述两条件，则允许进程Pi访问该资源（即允许进入临界区）： ·Pi自身请求访问该资源的消息已处于请求队列的最前面； ·Pi已收到从所有其它进程发来的回答消息，这些回答消息的时间戳均晚于（Ti，i)。

（4）为了释放该资源，Pi从自己的队列中撤销请求消息，并发送一个打上时间戳的释 放消息release给其它进程；

(5）当进程Pj收到Pi的release消息后，它撤销自己队列中的原Pi的request(Ti,i)消息。

10.4.7令牌环算法 一一一一一一→ 该算法属于分布式同步算法，是将所有进程组成一个逻辑环(LogicalRing)，系统中设 置一个象征存取权力的令牌（Token)，它是一种特定格式的报文，在进程所组成的逻辑环中， 不断地循环传递，获得令牌的进程，才有权力进入临界区，访问共享资源。 个进程获得令牌时，如果不需要访问共享资源，则将令牌继续传递下去。否则，保持令牌， 对共享资源进行检查，如果其空闲，则进入临界区进行访问。访问结束退出临界区后，再 将令牌继续传递下去。进程利用令牌，每次只能访问一次共享资源。 显然，由于令牌只有一个，任何一个时刻，只有一个进程能够持有令牌，因此能实现 对共享资源的互斥访问。 为保证环中进程能实现对共享资源的访问，逻辑环中的令牌必须保持循环传递和不丢 失，如果因通信链路、进程故障等原因造成令牌被破坏或丢失，必须有机制及时修复，比 如重新颁发令牌，或者屏蔽故障进程，重构逻辑环等。该算法的不足之处在于，如果令牌 丢失或破坏，不便进行检测和判断。 /10.5多处理机系统的进程调度 在多处理机系统中，进程的调度与系统结构有关。例如，在同构型系统中，由于所有 的处理机都是相同的，因而可将进程分配到任一处理机上运行；但对于非对称多处理机系 326